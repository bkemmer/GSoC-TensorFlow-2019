{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_app",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WWXJT7w4hs1"
      },
      "source": [
        "# following tips from the  post: https://medium.com/@robertbracco1/configuring-google-colab-like-a-pro-d61c253f7573"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "W9XQOA-E9g3i",
        "outputId": "c507320b-f3d5-4718-c316-4c9d1b44372b"
      },
      "source": [
        "%%javascript\n",
        "function ClickConnect(){  \n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "function ClickConnect(){  \n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}setInterval(ClickConnect,60000)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhaNxufN26XG",
        "outputId": "0321d75c-623d-4b9c-8ced-a4741dad1f05"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOHbbVaW2_-h",
        "outputId": "167d9999-4273-4bab-cd2d-340fcfe708a5"
      },
      "source": [
        "!ls -al '/content/drive/MyDrive/Face Aging'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "drwx------ 2 root root 4096 Apr 11 21:37 cGAN\n",
            "drwx------ 2 root root 4096 Mar 21 22:58 data\n",
            "drwx------ 2 root root 4096 Mar 23 22:42 models\n",
            "drwx------ 2 root root 4096 Mar 21 22:58 notebooks\n",
            "drwx------ 2 root root 4096 Mar 21 22:58 src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RArV40qL3nbk",
        "outputId": "2c51976b-95ad-4953-ddbd-1dfad166011e"
      },
      "source": [
        "# !mkdir -p '/content/drive/MyDrive/Face Aging/cGAN/data'\n",
        "# !touch '/content/drive/MyDrive/Face Aging/cGAN/.gitkeep'\n",
        "!ls -al '/content/drive/MyDrive/Face Aging/cGAN/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 12\n",
            "drwx------ 2 root root 4096 Apr 11 22:06 data\n",
            "-rw------- 1 root root    0 Apr 11 21:38 .gitkeep\n",
            "drwx------ 2 root root 4096 Apr 12 00:09 models\n",
            "drwx------ 2 root root 4096 Apr 12 00:09 results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJJe27kg3NZg"
      },
      "source": [
        "# ! wget -c -P '/content/drive/MyDrive/Face Aging/cGAN/data/' https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nal1_W70-1Ub",
        "outputId": "3503ffcf-ca27-4f4a-92d2-cd728ccfc4f9"
      },
      "source": [
        "! ls -al '/content/drive/MyDrive/Face Aging/cGAN/data'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 792304\n",
            "drwx------ 2 root root      4096 Apr 11 22:13 wiki_crop\n",
            "-rw------- 1 root root 811315200 Feb 23  2016 wiki_crop.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWd7tJCg-tgK"
      },
      "source": [
        "# ! tar -C /myfolder -xvf file_name.tar ### example\n",
        "# ! tar -C '/content/drive/MyDrive/Face Aging/cGAN/data/' -xf '/content/drive/MyDrive/Face Aging/cGAN/data/wiki_crop.tar'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhj2uXgl_jhE",
        "outputId": "b30478ec-0fbc-4809-9034-473bbeb60f11"
      },
      "source": [
        "! ls '/content/drive/MyDrive/Face Aging/cGAN/data/wiki_crop'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00  06\t12  18\t24  30\t36  42\t48  54\t60  66\t72  78\t84  90\t96\n",
            "01  07\t13  19\t25  31\t37  43\t49  55\t61  67\t73  79\t85  91\t97\n",
            "02  08\t14  20\t26  32\t38  44\t50  56\t62  68\t74  80\t86  92\t98\n",
            "03  09\t15  21\t27  33\t39  45\t51  57\t63  69\t75  81\t87  93\t99\n",
            "04  10\t16  22\t28  34\t40  46\t52  58\t64  70\t76  82\t88  94\twiki.mat\n",
            "05  11\t17  23\t29  35\t41  47\t53  59\t65  71\t77  83\t89  95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0-JUKfx4Dk5"
      },
      "source": [
        "# # Tip 4: Use Gdown to grab publicly available Google Drive files\n",
        "\n",
        "# ## Command Line\n",
        "# # note, your file_id can be found in the shareable link of the file\n",
        "# ! pip install gdown -q\n",
        "# ! gdown — id <file_id>## In Python\n",
        "# import gdown\n",
        "# url = https://drive.google.com/uc?id=<file_id>\n",
        "# output = 'my_archive.tar'\n",
        "# gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epb52AQ-4MUw"
      },
      "source": [
        "# !git config --global user.email brunokemmer@gmail.com\n",
        "# !git config --global user.name Bruno Kemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfcIeHR_5sVH"
      },
      "source": [
        "# https://github.com/Vishal-V/GSoC-TensorFlow-2019.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4y5Dptf4S1Q",
        "outputId": "426c3fec-af3c-404a-8ad5-74f3bf701fb8"
      },
      "source": [
        "# import os\n",
        "# from getpass import getpass\n",
        "# import urllib\n",
        "\n",
        "# user = 'Vishal-V'\n",
        "# password = getpass('Password: ')\n",
        "# repo_name = 'GSoC-TensorFlow-2019'\n",
        "\n",
        "# # your password is converted into url format\n",
        "# password = urllib.parse.quote(password)\n",
        "\n",
        "# cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, repo_name)\n",
        "# os.system(cmd_string)\n",
        "\n",
        "# cmd_string, password = \"\", \"\" # removing the password from the variable\n",
        "\n",
        "# # Bad password fails silently so make sure the repo was copied\n",
        "# assert os.path.exists(f\"/content/{repo_name}\"), \"Incorrect Password or Repo Not Found, please try again\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5Puu9f06AEP",
        "outputId": "d038fd3c-0074-408a-c95b-4504ecea1228"
      },
      "source": [
        "# !ls /content/{repo_name}/face_app"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_download.py  __init__.py  model.py  notebook  README.md  requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5om5mNb16HYY"
      },
      "source": [
        "# !python /content/{repo_name}/face_app/data_download.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QpuZHdJ9XuY",
        "outputId": "e778187c-336c-4f3b-809c-4f0f9c9345d7"
      },
      "source": [
        "# !ls /content/{repo_name}/face_app"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_download.py  __init__.py  model.py  notebook  README.md  requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNubPh1oRUi1",
        "outputId": "96d28c6c-7bd7-4b12-a35f-6d76e8e46a40"
      },
      "source": [
        "! pip install fastprogress\n",
        "from fastprogress import master_bar, progress_bar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastprogress in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fastprogress) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aZmfeO4A9JIu",
        "outputId": "70dffab0-f6d8-46b4-b798-581a136cb412"
      },
      "source": [
        "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Age-cGAN Model.\n",
        "\n",
        "Dataset Citation:\n",
        "@article{Rothe-IJCV-2016,\n",
        "  author = {Rasmus Rothe and Radu Timofte and Luc Van Gool},\n",
        "  title = {Deep expectation of real and apparent age from a single image without facial landmarks},\n",
        "  journal = {International Journal of Computer Vision (IJCV)},\n",
        "  year = {2016},\n",
        "  month = {July},\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import gc\n",
        "from absl import app\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2.')\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from datetime import datetime\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, UpSampling2D, Conv2D, Activation, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2DTranspose, add, ZeroPadding2D, LeakyReLU\n",
        "from tensorflow.keras.layers import Lambda, Reshape, Flatten, concatenate, Dropout\n",
        "import tensorflow.keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from fastprogress import master_bar, progress_bar\n",
        "\n",
        "\n",
        "def compute_age(photo_date, dob):\n",
        "    \"\"\"Calculates the age from the dob and the date of photo taken.\n",
        "    \"\"\"\n",
        "    birth = datetime.fromordinal(max(int(dob) - 366, 1))\n",
        "    if birth.month < 7:\n",
        "        return photo_date - birth.year\n",
        "    else:\n",
        "        return photo_date - birth.year - 1\n",
        "\n",
        "def load_data(path):\n",
        "    \"\"\"Loads the image paths and the calculated ages for each photo. \n",
        "    \"\"\"\n",
        "    metadata = loadmat(os.path.join(path, \"wiki.mat\"))\n",
        "    paths = metadata['wiki'][0, 0]['full_path'][0]\n",
        "    dob = metadata['wiki'][0, 0]['dob'][0]\n",
        "    photo_date = metadata['wiki'][0, 0]['photo_taken'][0]\n",
        "    calculated_age = [compute_age(photo_date[i], dob[i]) for i in range(len(dob))]\n",
        "\n",
        "    images = []\n",
        "    ages_list = []\n",
        "\n",
        "    for i, image_path in enumerate(paths):\n",
        "        images.append(image_path[0])\n",
        "        ages_list.append(calculated_age[i])\n",
        "\n",
        "    return images, ages_list\n",
        "\n",
        "def make_encoder():\n",
        "    \"\"\"Builds the Encoder network.\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=(64, 64, 3))\n",
        "    x = Conv2D(32, (5,5), strides=2, padding='same', kernel_initializer='he_uniform')(input_layer)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(64, (5,5), strides=2, padding='same', kernel_initializer='he_uniform')(input_layer)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(128, (5,5), strides=2, padding='same', kernel_initializer='he_uniform')(input_layer)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(256, (5,5), strides=2, padding='same', kernel_initializer='he_uniform')(input_layer)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(4096)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Dense(100)(x)\n",
        "\n",
        "    return Model(inputs=[input_layer], outputs=[x])\n",
        "\n",
        "\n",
        "def make_generator():\n",
        "    \"\"\"Builds the Generator network.\n",
        "    \"\"\"\n",
        "    latent_vector = Input(shape=(100,))\n",
        "    conditioning_variable = Input(shape=(6,))\n",
        "\n",
        "    x = concatenate([latent_vector, conditioning_variable])\n",
        "\n",
        "    x = Dense(2048, input_dim=106)(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Dense(16384)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Reshape((8, 8, 256))(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2,2))(x)\n",
        "    x = Conv2D(128, (5,5), padding='same', kernel_initializer='he_uniform')(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2,2))(x)\n",
        "    x = Conv2D(64, (5,5), padding='same', kernel_initializer='he_uniform')(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2,2))(x)\n",
        "    x = Conv2D(3, (5,5), padding='same', kernel_initializer='he_uniform')(x)\n",
        "    x = Activation('tanh')(x)\n",
        "\n",
        "    return Model(inputs=[latent_vector, conditioning_variable], outputs=[x])\n",
        "\n",
        "\n",
        "def make_face_recognition(shape):\n",
        "    \"\"\"Builds the Face Recognition Network.\n",
        "    \"\"\"\n",
        "    model = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=shape, pooling='avg')\n",
        "    image = model.input\n",
        "    x = model.layers[-1].output\n",
        "    outputs = Dense(128)(x)\n",
        "    embedding_model = Model(inputs=[image], outputs=[outputs])\n",
        "\n",
        "    input_layer = Input(shape=shape)\n",
        "    x = embedding_model(input_layer)\n",
        "    outputs = Lambda(lambda x: tf.keras.backend.l2_normalize(x, -1))(x)\n",
        "    return Model(inputs=[input_layer], outputs=[outputs])\n",
        "\n",
        "def save_image(img, path):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "def expand_dims(label):\n",
        "    \"\"\"Increases dimensions along the specified axis.\n",
        "    \"\"\"\n",
        "    label = tf.keras.backend.expand_dims(label, 1)\n",
        "    label = tf.keras.backend.expand_dims(label, 1)\n",
        "    return tf.keras.backend.tile(label, [1, 32, 32, 1])\n",
        "\n",
        "def make_resize():\n",
        "    \"\"\"Returns the image resize model.\n",
        "    \"\"\"\n",
        "    input_image = Input(shape=(64, 64, 3))\n",
        "    resized_image = Lambda(lambda x: K.resize_images(x, height_factor=3, width_factor=3,\n",
        "                                    data_format='channels_last'))(input_image)\n",
        "    return Model(inputs=[input_image], outputs=[resized_image])\n",
        "\n",
        "def make_discriminator():\n",
        "    \"\"\"Builds the Discriminator network.\n",
        "    \"\"\"\n",
        "    image_input = Input(shape=(64, 64, 3))\n",
        "    label_input = Input(shape=(6,))\n",
        "\n",
        "    x = Conv2D(64, (3,3), strides=2, padding='same', kernel_initializer='he_uniform')(image_input)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    label = Lambda(expand_dims)(label_input)\n",
        "    \n",
        "    x = concatenate([x, label], axis=3)\n",
        "    x = Conv2D(128, (3,3), strides=2, padding='same', kernel_initializer='he_uniform')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(256, (3,3), strides=2, padding='same', kernel_initializer='he_uniform')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(512, (3,3), strides=2, padding='same', kernel_initializer='he_uniform')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    return Model(inputs=[image_input, label_input], outputs=[x])\n",
        "\n",
        "\n",
        "def make_adversarial(generator, discriminator):\n",
        "    \"\"\"Builds the Adversarial Network.\n",
        "    \"\"\"\n",
        "    latent_space = Input(shape=(100,))\n",
        "    conditioning_variable = Input(shape=(6,))\n",
        "\n",
        "    discriminator.trainable = False\n",
        "    reconstructed = generator([latent_space, conditioning_variable])\n",
        "    valid = discriminator([reconstructed, conditioning_variable])\n",
        "\n",
        "    discriminator.trainable = True\n",
        "    return Model(inputs=[latent_space, conditioning_variable], outputs=[valid])\n",
        "\n",
        "\n",
        "def get_age_categories(ages):\n",
        "    age_list = []\n",
        "    for age in ages:\n",
        "        if 0 < age <= 18:\n",
        "            age_list.append(0)\n",
        "        elif 18 < age <= 29:\n",
        "            age_list.append(1)\n",
        "        elif 29 < age <= 39:\n",
        "            age_list.append(2)\n",
        "        elif 39 < age <= 49:\n",
        "            age_list.append(3)\n",
        "        elif 49 < age <= 59:\n",
        "            age_list.append(4)\n",
        "        elif age >= 60:\n",
        "            age_list.append(5)\n",
        "\n",
        "    return age_list\n",
        "\n",
        "def load_images(path, image_paths, shape):\n",
        "    \"\"\"Returns all the images as a variable of concatenated arrays.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    # image_ = None\n",
        "    # for i, image_path in enumerate(image_paths):\n",
        "    for image_path in progress_bar(image_paths):\n",
        "        try:\n",
        "            image = tf.keras.preprocessing.image.load_img(os.path.join(path, image_path),\n",
        "                        target_size=shape)\n",
        "            image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "            image = np.expand_dims(image, axis=0)\n",
        "            images.append(image)\n",
        "            # if image_ is None:\n",
        "                # image_ = image\n",
        "            # else:\n",
        "                # image_ = np.concatenate([image_, image], axis=0)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'Error! Image {i} {e}')\n",
        "\n",
        "    # return image_\n",
        "    return np.concatenate(images, axis=0)\n",
        "\n",
        "def euclidean_loss(y_true, y_pred):\n",
        "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))\n",
        "\n",
        "def resize(input_image, real_image, height, width):\n",
        "  input_image = tf.image.resize(input_image, [height, width],\n",
        "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  real_image = tf.image.resize(real_image, [height, width],\n",
        "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "  return input_image, real_image\n",
        "\n",
        "# def run_main(argv):\n",
        "#     # del argv\n",
        "#     kwargs = {'path' : DATASET_PATH}\n",
        "#     main(**kwargs)\n",
        "\n",
        "def main(DATASET_PATH, BASE_MODELS_PATH, BASE_RESULTS_PATH, process_load_images=True,\n",
        "         TRAIN_GAN = True, TRAIN_ENCODER = True, TRAIN_ENC_GAN = True):\n",
        "    \"\"\"The training of the Age-cGAN occurs in 3 steps:\n",
        "        1. Training the Generator and Discriminator Networks.\n",
        "        2. Initial Latent Vector Approximation (Encoder).\n",
        "        3. Latent Vector Optimization (Encoder and Generator).\n",
        "    \"\"\"\n",
        "    epochs = 250 # 250\n",
        "    batch_size = 128 # Change to 1 in case of ConcatOp error\n",
        "    # TRAIN_GAN = True # Step 1\n",
        "    # TRAIN_ENCODER = True # Step 2\n",
        "    # TRAIN_ENC_GAN = True # Step 3\n",
        "    latent_shape = 100\n",
        "    image_shape = (64, 64, 3)\n",
        "    fr_image_shape = (192, 192, 3)\n",
        "    gen_opt = tf.keras.optimizers.Adam(lr=0.002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
        "    dis_opt = tf.keras.optimizers.Adam(lr=0.002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
        "    adv_opt = tf.keras.optimizers.Adam(lr=0.002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
        "\n",
        "    generator = make_generator()\n",
        "    generator.compile(loss='binary_crossentropy', optimizer=gen_opt)\n",
        "\n",
        "    discriminator = make_discriminator()\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=dis_opt)\n",
        "\n",
        "    adversarial = make_adversarial(generator, discriminator)\n",
        "    adversarial.compile(loss='binary_crossentropy', optimizer=adv_opt)\n",
        "\n",
        "    images, age_list = load_data(DATASET_PATH)\n",
        "    print(f\"len(images): {len(images)}, len(age_list): {len(age_list)}\")\n",
        "\n",
        "    categories = get_age_categories(age_list)\n",
        "    print(f\"len(categories): {len(categories)}\")\n",
        "    age_categories = np.reshape(np.array(categories), [len(categories), 1])\n",
        "    num_classes = len(set(categories))\n",
        "    y = to_categorical(age_categories, num_classes=num_classes)\n",
        "    print(f\"shape(y): {y.shape}\")\n",
        "    print(f'Loaded labels and image paths. Preparing to load images...')\n",
        "\n",
        "    if process_load_images:\n",
        "        loaded_images = load_images(DATASET_PATH, images, (image_shape[0], image_shape[1]))\n",
        "        np.save(BASE_MODELS_PATH + 'loaded_images.npy', loaded_images, allow_pickle=True)\n",
        "    else:\n",
        "        loaded_images = np.load(BASE_MODELS_PATH + 'loaded_images.npy', allow_pickle=True)\n",
        "\n",
        "    print(f'Loaded all images into an array.')\n",
        "\n",
        "    real = np.ones((batch_size, 1), dtype=np.float32) * 0.9\n",
        "    fake = np.zeros((batch_size, 1), dtype=np.float32) * 0.1\n",
        "\n",
        "    # Train Step 1: Train the Generator and Discriminator\n",
        "    if TRAIN_GAN:\n",
        "        print(f'Step 1: Training the Generator and Discriminator')\n",
        "        mb_epochs = master_bar(range(epochs))\n",
        "        for epoch in mb_epochs:\n",
        "            print(f'Epoch:{epoch}')\n",
        "\n",
        "            num_batches = int(len(loaded_images)/batch_size)\n",
        "            for i in progress_bar(range(num_batches), parent=mb_epochs):\n",
        "                batch = loaded_images[i*batch_size:(i+1)*batch_size]\n",
        "                batch = batch / 127.5 - 1.\n",
        "                batch = batch.astype(np.float32)\n",
        "\n",
        "                latent_vector = np.random.normal(0, 1, size=(batch_size, 100))\n",
        "                y_curr = y[i*batch_size:(i+1)*batch_size]\n",
        "\n",
        "                reconstructed = generator.predict_on_batch([latent_vector, y_curr])\n",
        "                d_real = discriminator.train_on_batch([batch, y_curr], [real])\n",
        "                d_recons = discriminator.train_on_batch([reconstructed, y_curr], [fake])\n",
        "                d_curr = 0.5 * np.add(d_real, d_recons)\n",
        "\n",
        "                latent_space = np.random.normal(0, 1, size=(batch_size, 100))\n",
        "                conditioning_variable = np.random.randint(0, 6, batch_size).reshape(-1, 1)\n",
        "                conditioning_variable = to_categorical(conditioning_variable, num_classes=6)\n",
        "\n",
        "                g_curr = adversarial.train_on_batch([latent_space, conditioning_variable], np.array([1]*batch_size))\n",
        "                print(f'Gen_loss:{g_curr}\\nDisc_loss:{d_curr}')\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                mini_batch = loaded_images[:batch_size]\n",
        "                mini_batch = mini_batch / 127.5 - 1.\n",
        "                mini_batch = mini_batch.astype(np.float32)\n",
        "\n",
        "                y_batch = y[:batch_size]\n",
        "                latent_space = np.random.normal(0, 1, size=(batch_size, 100))\n",
        "\n",
        "                gen = generator.predict_on_batch([latent_space, y_batch])\n",
        "\n",
        "                for i, image in enumerate(gen[:10]):\n",
        "                    save_image(image, path=f'{BASE_RESULTS_PATH}image_{epoch}_{i}')\n",
        "\n",
        "            if epoch % 25 == 0:\n",
        "                generator.save_weights(BASE_MODELS_PATH + \"generator.h5\")\n",
        "                discriminator.save_weights(BASE_MODELS_PATH + \"discriminator.h5\")\n",
        "                adversarial.save_weights(BASE_MODELS_PATH + \"adversarial.h5\")\n",
        "\n",
        "        generator.save_weights(BASE_MODELS_PATH + \"generator.h5\")\n",
        "        discriminator.save_weights(BASE_MODELS_PATH + \"discriminator.h5\")\n",
        "        adversarial.save_weights(BASE_MODELS_PATH + \"adversarial.h5\")\n",
        "\n",
        "        tf.keras.backend.clear_session()\n",
        "        del generator\n",
        "        del discriminator\n",
        "        del adversarial\n",
        "        gc.collect()\n",
        "\n",
        "    # Train Step 2: Train the Encoder\n",
        "    if TRAIN_ENCODER:\n",
        "        print(f'Step 2: Training the Encoder - Latent Vector Approximation')\n",
        "        encoder = make_encoder()\n",
        "        encoder.compile(loss=euclidean_loss, optimizer=tf.keras.optimizers.Adam())\n",
        "\n",
        "        generator.load_weights(BASE_MODELS_PATH + 'generator.h5')\n",
        "                \n",
        "        latent_vector = np.random.normal(0, 1, size=(5000, 100))\n",
        "        y = np.random.randint(0, 6, size=(5000,), dtype=np.int64)\n",
        "        num_classes = len(set(y))\n",
        "        y = np.reshape(np.array(y), [len(y), 1])\n",
        "        y = to_categorical(y, num_classes=num_classes)\n",
        "        mb_epochs = master_bar(range(epochs))\n",
        "        for epoch in mb_epochs:\n",
        "            print(f'Epoch: {epoch}')\n",
        "\n",
        "            num_batches = int(len(latent_vector.shape[0])/batch_size)\n",
        "            for i in progress_bar(range(batch_size)):\n",
        "\n",
        "                latent_batch = latent_vector[i*batch_size:(i+1)*batch_size]\n",
        "                y_batch = y[i*batch_size:(i+1)*batch_size]\n",
        "\n",
        "                reconstructed = generator.predict_on_batch([latent_batch, y_batch])\n",
        "                e_loss = encoder.train_on_batch(reconstructed, latent_batch)\n",
        "\n",
        "            print(f'Encoder_loss: {e_loss}')\n",
        "\n",
        "            if epoch % 25 == 0:\n",
        "                encoder.save_weights(BASE_MODELS_PATH + 'encoder.h5')\n",
        "\n",
        "        encoder.save_weights(BASE_MODELS_PATH + 'encoder.h5')\n",
        "\n",
        "        tf.keras.backend.clear_session()\n",
        "        del encoder\n",
        "        gc.collect()\n",
        "\n",
        "    # Train Step 3: Train the Generator and Encoder and Generator\n",
        "    if TRAIN_ENC_GAN:\n",
        "        print(f'Step 3: Training the Generator and Encoder. Latent Vector Optimization')\n",
        "        encoder = make_encoder()\n",
        "        encoder.load_weights(BASE_MODELS_PATH + 'encoder.h5')\n",
        "        generator = make_generator()\n",
        "        generator.load_weights(BASE_MODELS_PATH + 'generator.h5')\n",
        "        resize_model = make_resize()\n",
        "        resize_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam())\n",
        "\n",
        "        face_rec = make_face_recognition(fr_image_shape)\n",
        "        face_rec.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam())\n",
        "        face_rec.trainable = False\n",
        "\n",
        "        image_input = Input(shape=(64, 64, 3))\n",
        "        conditioning_variable = Input(shape=(6,))\n",
        "\n",
        "        latent_approximation = encoder(image_input)\n",
        "        reconstruction = generator([latent_approximation, conditioning_variable])\n",
        "\n",
        "        # fr_resized_images = tf.image.resize(reconstruction, [192, 192], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "        fr_resized_images = Lambda(lambda x: K.resize_images(x, height_factor=3, width_factor=3,\n",
        "                                                          data_format='channels_last'))(reconstruction)\n",
        "        embeddings = face_rec(fr_resized_images)\n",
        "\n",
        "        fr_adversarial = Model(inputs=[image_input, conditioning_variable], outputs=[embeddings])\n",
        "        fr_adversarial.compile(loss=euclidean_loss, optimizer=adv_opt)\n",
        "\n",
        "        mb_epochs = master_bar(range(epochs))\n",
        "        for epoch in mb_epochs:\n",
        "            print(f'Epoch: {epoch}')\n",
        "\n",
        "            num_batches = int(len(loaded_images)/batch_size)\n",
        "            for i in progress_bar(range(num_batches), parent = mb_epochs):\n",
        "                batch = loaded_images[i*batch_size:(i+1)*batch_size]\n",
        "                batch = batch / 127.5 - 1.\n",
        "                batch = batch.astype(np.float32)\n",
        "                y_batch = y[i*batch_size:(i+1)*batch_size]\n",
        "\n",
        "                resized_image_batch = resize_model.predict_on_batch([batch])\n",
        "                embeds = face_rec.predict_on_batch([resized_image_batch])\n",
        "                loss = fr_adversarial.train_on_batch([batch, y_batch], embeds)\n",
        "\n",
        "            print(f'Reconstruction Loss: {loss}')\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                generator.save_weights(BASE_MODELS_PATH + 'opt_generator.h5')\n",
        "                encoder.save_weights(BASE_MODELS_PATH + 'opt_encoder.h5')\n",
        "\n",
        "        generator.save_weights(BASE_MODELS_PATH + 'opt_generator.h5')\n",
        "        encoder.save_weights(BASE_MODELS_PATH + 'opt_encoder.h5')\n",
        "\n",
        "        tf.keras.backend.clear_session()\n",
        "        del generator\n",
        "        del encoder\n",
        "        gc.collect()\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "    # app.run(run_main)\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Face Aging/cGAN/data/wiki_crop\"\n",
        "BASE_MODELS_PATH = \"/content/drive/MyDrive/Face Aging/cGAN/models/\"\n",
        "BASE_RESULTS_PATH = \"/content/drive/MyDrive/Face Aging/cGAN/results/\"\n",
        "\n",
        "[Path(x).mkdir(parents=True, exist_ok=True) for x in [DATASET_PATH, BASE_MODELS_PATH, BASE_RESULTS_PATH]]\n",
        "\n",
        "main(DATASET_PATH, BASE_MODELS_PATH, BASE_RESULTS_PATH, process_load_images=False,\n",
        "     TRAIN_GAN = True, TRAIN_ENCODER = False, TRAIN_ENC_GAN = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(images): 62328, len(age_list): 62328\n",
            "len(categories): 60942\n",
            "shape(y): (60942, 6)\n",
            "Loaded labels and image paths. Preparing to load images...\n",
            "Loaded all images into an array.\n",
            "Step 1: Training the Generator and Discriminator\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/250 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='476' class='' max='486' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      97.94% [476/486 04:01<00:05]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:0\n",
            "Gen_loss:0.8975032567977905\n",
            "Disc_loss:6.738068133592606\n",
            "Gen_loss:4.969631195068359\n",
            "Disc_loss:6.292323470115662\n",
            "Gen_loss:4.341814994812012\n",
            "Disc_loss:5.998910844326019\n",
            "Gen_loss:2.187631845474243\n",
            "Disc_loss:1.4504441320896149\n",
            "Gen_loss:0.7842029333114624\n",
            "Disc_loss:0.882472813129425\n",
            "Gen_loss:0.47704213857650757\n",
            "Disc_loss:0.5553298145532608\n",
            "Gen_loss:0.1765563040971756\n",
            "Disc_loss:0.44532226026058197\n",
            "Gen_loss:0.00956102553755045\n",
            "Disc_loss:0.2522067427635193\n",
            "Gen_loss:0.0013023732462897897\n",
            "Disc_loss:0.21171374805271626\n",
            "Gen_loss:0.000530762248672545\n",
            "Disc_loss:0.19995546713471413\n",
            "Gen_loss:0.0012496752897277474\n",
            "Disc_loss:0.19327306700870395\n",
            "Gen_loss:0.0013338923454284668\n",
            "Disc_loss:0.18491989106405526\n",
            "Gen_loss:0.0007955190958455205\n",
            "Disc_loss:0.18200243986211717\n",
            "Gen_loss:0.0010049105621874332\n",
            "Disc_loss:0.19269175734370947\n",
            "Gen_loss:0.0008246883517131209\n",
            "Disc_loss:0.18383800704032183\n",
            "Gen_loss:0.0007749550277367234\n",
            "Disc_loss:0.1869986626552418\n",
            "Gen_loss:0.001740389852784574\n",
            "Disc_loss:0.18251313414657488\n",
            "Gen_loss:0.0006943566841073334\n",
            "Disc_loss:0.1883486876031384\n",
            "Gen_loss:0.0025907307863235474\n",
            "Disc_loss:0.17988046974642202\n",
            "Gen_loss:0.0010566826676949859\n",
            "Disc_loss:0.17597480566473678\n",
            "Gen_loss:0.0010606036521494389\n",
            "Disc_loss:0.17575018166098744\n",
            "Gen_loss:0.001128369360230863\n",
            "Disc_loss:0.173699205275625\n",
            "Gen_loss:0.0010968550341203809\n",
            "Disc_loss:0.1754246959462762\n",
            "Gen_loss:0.0016894949367269874\n",
            "Disc_loss:0.17648987809661776\n",
            "Gen_loss:0.000823814538307488\n",
            "Disc_loss:0.18409311526920646\n",
            "Gen_loss:0.010450939647853374\n",
            "Disc_loss:0.24663341394625604\n",
            "Gen_loss:4.597442602971569e-05\n",
            "Disc_loss:0.38927882816642523\n",
            "Gen_loss:0.00043312733760103583\n",
            "Disc_loss:0.350576676428318\n",
            "Gen_loss:0.0012707756832242012\n",
            "Disc_loss:0.252662048307684\n",
            "Gen_loss:0.0010379949817433953\n",
            "Disc_loss:0.21502702595262235\n",
            "Gen_loss:0.0018455680692568421\n",
            "Disc_loss:0.19781769297333085\n",
            "Gen_loss:0.0012424837332218885\n",
            "Disc_loss:0.17322072784008924\n",
            "Gen_loss:0.0012665430549532175\n",
            "Disc_loss:0.17709172460672562\n",
            "Gen_loss:0.0018218484474346042\n",
            "Disc_loss:0.17714511447775294\n",
            "Gen_loss:0.001571615575812757\n",
            "Disc_loss:0.18496711153602519\n",
            "Gen_loss:0.0012487727217376232\n",
            "Disc_loss:0.17533501684374642\n",
            "Gen_loss:0.0013216290390118957\n",
            "Disc_loss:0.173832706437679\n",
            "Gen_loss:0.0014503817074000835\n",
            "Disc_loss:0.17337438191316323\n",
            "Gen_loss:0.0016849108505994081\n",
            "Disc_loss:0.2104500637651654\n",
            "Gen_loss:0.00044164108112454414\n",
            "Disc_loss:0.23040434112772346\n",
            "Gen_loss:0.0005359771312214434\n",
            "Disc_loss:0.28112349030561745\n",
            "Gen_loss:0.0006451960653066635\n",
            "Disc_loss:0.25030867027817294\n",
            "Gen_loss:0.0011274013668298721\n",
            "Disc_loss:0.20980913925086497\n",
            "Gen_loss:0.0017436505295336246\n",
            "Disc_loss:0.17707724507999956\n",
            "Gen_loss:0.0014802328078076243\n",
            "Disc_loss:0.16966431503897184\n",
            "Gen_loss:0.0014990323688834906\n",
            "Disc_loss:0.16939084200566867\n",
            "Gen_loss:0.0012760964455083013\n",
            "Disc_loss:0.16582190514964168\n",
            "Gen_loss:0.0016692333156242967\n",
            "Disc_loss:0.1660980744927656\n",
            "Gen_loss:0.000990325934253633\n",
            "Disc_loss:0.16866588943594252\n",
            "Gen_loss:0.0008999269921332598\n",
            "Disc_loss:0.1712693601512001\n",
            "Gen_loss:0.0009313998161815107\n",
            "Disc_loss:0.16977526305709034\n",
            "Gen_loss:0.0005493541830219328\n",
            "Disc_loss:0.18562161570298485\n",
            "Gen_loss:0.0007062570657581091\n",
            "Disc_loss:0.18543102088733576\n",
            "Gen_loss:0.0014825984835624695\n",
            "Disc_loss:0.1729471241196734\n",
            "Gen_loss:0.0005196812562644482\n",
            "Disc_loss:0.1701574009930482\n",
            "Gen_loss:0.0008016843348741531\n",
            "Disc_loss:0.17213296322734095\n",
            "Gen_loss:0.0006061617168597877\n",
            "Disc_loss:0.1674485778057715\n",
            "Gen_loss:0.001091453363187611\n",
            "Disc_loss:0.1692637862142874\n",
            "Gen_loss:0.0006468431674875319\n",
            "Disc_loss:0.1717616605310468\n",
            "Gen_loss:0.00035422027576714754\n",
            "Disc_loss:0.19836085606948473\n",
            "Gen_loss:0.0003286799765191972\n",
            "Disc_loss:0.19633292497019283\n",
            "Gen_loss:0.0009230459108948708\n",
            "Disc_loss:0.18306859175208956\n",
            "Gen_loss:0.0006438633427023888\n",
            "Disc_loss:0.1673279561509844\n",
            "Gen_loss:0.0007142713293433189\n",
            "Disc_loss:0.16693392704473808\n",
            "Gen_loss:0.0007610160391777754\n",
            "Disc_loss:0.16597542756062467\n",
            "Gen_loss:0.0007576117641292512\n",
            "Disc_loss:0.1660873945511412\n",
            "Gen_loss:0.0006171532440930605\n",
            "Disc_loss:0.17619527303031646\n",
            "Gen_loss:0.00017604512686375529\n",
            "Disc_loss:0.2324166283942759\n",
            "Gen_loss:0.00027898058760911226\n",
            "Disc_loss:0.25349611695855856\n",
            "Gen_loss:0.0005440281238406897\n",
            "Disc_loss:0.21387750591384247\n",
            "Gen_loss:0.0005773080629296601\n",
            "Disc_loss:0.20583452125720214\n",
            "Gen_loss:0.0011688724625855684\n",
            "Disc_loss:0.17343207701924257\n",
            "Gen_loss:0.0041518015787005424\n",
            "Disc_loss:0.17909564685760415\n",
            "Gen_loss:0.0026096387300640345\n",
            "Disc_loss:0.26848889922257513\n",
            "Gen_loss:8.172616617230233e-06\n",
            "Disc_loss:0.5853595566004515\n",
            "Gen_loss:0.00037987169343978167\n",
            "Disc_loss:0.5060871919849887\n",
            "Gen_loss:0.004574173130095005\n",
            "Disc_loss:0.4281227106694132\n",
            "Gen_loss:0.00015036882541608065\n",
            "Disc_loss:0.3800615929067135\n",
            "Gen_loss:0.00030267692636698484\n",
            "Disc_loss:0.3104073434442398\n",
            "Gen_loss:0.003557410789653659\n",
            "Disc_loss:0.22574676987642306\n",
            "Gen_loss:0.0007327118655666709\n",
            "Disc_loss:0.2156305426324252\n",
            "Gen_loss:0.0008017703657969832\n",
            "Disc_loss:0.22754262076341547\n",
            "Gen_loss:0.002280453685671091\n",
            "Disc_loss:0.1948371712860535\n",
            "Gen_loss:0.0017166550969704986\n",
            "Disc_loss:0.17747546073951526\n",
            "Gen_loss:0.0011849630391225219\n",
            "Disc_loss:0.1808766599642695\n",
            "Gen_loss:0.0011582339648157358\n",
            "Disc_loss:0.18302707353723235\n",
            "Gen_loss:0.0010609227465465665\n",
            "Disc_loss:0.16668131250844453\n",
            "Gen_loss:0.000994788482785225\n",
            "Disc_loss:0.1684999059434631\n",
            "Gen_loss:0.0007332471432164311\n",
            "Disc_loss:0.17268253427027958\n",
            "Gen_loss:0.00032937576179392636\n",
            "Disc_loss:0.2071515797288157\n",
            "Gen_loss:0.0006765478756278753\n",
            "Disc_loss:0.19139853820524877\n",
            "Gen_loss:0.0008445312851108611\n",
            "Disc_loss:0.1810261915488809\n",
            "Gen_loss:0.0007536226767115295\n",
            "Disc_loss:0.17194511155685177\n",
            "Gen_loss:0.0006586022791452706\n",
            "Disc_loss:0.178443634766154\n",
            "Gen_loss:9.915979899233207e-05\n",
            "Disc_loss:0.22935142746428028\n",
            "Gen_loss:0.0006993457209318876\n",
            "Disc_loss:0.22004868283693213\n",
            "Gen_loss:0.00040136027382686734\n",
            "Disc_loss:0.24754793822648935\n",
            "Gen_loss:1.9388266082387418e-05\n",
            "Disc_loss:0.31864625751040876\n",
            "Gen_loss:0.00012013384548481554\n",
            "Disc_loss:0.29478507296880707\n",
            "Gen_loss:0.00044191174674779177\n",
            "Disc_loss:0.2360787151264958\n",
            "Gen_loss:0.0006600128835998476\n",
            "Disc_loss:0.1882174113561632\n",
            "Gen_loss:0.0006595099112018943\n",
            "Disc_loss:0.18316469271667302\n",
            "Gen_loss:0.00011406688281567767\n",
            "Disc_loss:0.22393378237029538\n",
            "Gen_loss:0.0006451711524277925\n",
            "Disc_loss:0.2065963726490736\n",
            "Gen_loss:0.00033059646375477314\n",
            "Disc_loss:0.19884609399014153\n",
            "Gen_loss:0.0001416824961779639\n",
            "Disc_loss:0.21964332662173547\n",
            "Gen_loss:0.0005702549824491143\n",
            "Disc_loss:0.19320066268846858\n",
            "Gen_loss:0.000548443291336298\n",
            "Disc_loss:0.17274871628615074\n",
            "Gen_loss:0.00025336811086162925\n",
            "Disc_loss:0.18896019316161983\n",
            "Gen_loss:0.0002687807136680931\n",
            "Disc_loss:0.20045428660523612\n",
            "Gen_loss:0.00030104356119409204\n",
            "Disc_loss:0.189027586238808\n",
            "Gen_loss:0.0004783519543707371\n",
            "Disc_loss:0.17680249184195418\n",
            "Gen_loss:0.00018593535060063004\n",
            "Disc_loss:0.20584128849441186\n",
            "Gen_loss:0.00044820638140663505\n",
            "Disc_loss:0.23319444991648197\n",
            "Gen_loss:0.0012144092470407486\n",
            "Disc_loss:0.19480943882808788\n",
            "Gen_loss:0.0009060941520147026\n",
            "Disc_loss:0.17104591098905075\n",
            "Gen_loss:0.0007865336956456304\n",
            "Disc_loss:0.16802462423220277\n",
            "Gen_loss:0.0008510303450748324\n",
            "Disc_loss:0.16685717555810697\n",
            "Gen_loss:0.0006756177172064781\n",
            "Disc_loss:0.16573680330475327\n",
            "Gen_loss:0.0005432739271782339\n",
            "Disc_loss:0.16516655369196087\n",
            "Gen_loss:0.00042696468881331384\n",
            "Disc_loss:0.16440776709350757\n",
            "Gen_loss:0.0017124174628406763\n",
            "Disc_loss:0.17612254450796172\n",
            "Gen_loss:0.001313941553235054\n",
            "Disc_loss:0.21585183404386044\n",
            "Gen_loss:1.132018405769486e-05\n",
            "Disc_loss:0.47238332784036174\n",
            "Gen_loss:0.007334384135901928\n",
            "Disc_loss:0.44291983265429735\n",
            "Gen_loss:1.657463872106746e-05\n",
            "Disc_loss:0.3696868879487738\n",
            "Gen_loss:0.00023432253510691226\n",
            "Disc_loss:0.3295747218944598\n",
            "Gen_loss:0.0005057196249254048\n",
            "Disc_loss:0.2360519002104411\n",
            "Gen_loss:0.003071286715567112\n",
            "Disc_loss:0.18920614413218573\n",
            "Gen_loss:0.0003019853320438415\n",
            "Disc_loss:0.199426311039133\n",
            "Gen_loss:0.0012018335983157158\n",
            "Disc_loss:0.2293359947798308\n",
            "Gen_loss:0.00041872868314385414\n",
            "Disc_loss:0.2022864548198413\n",
            "Gen_loss:0.003760716412216425\n",
            "Disc_loss:0.20447145501384512\n",
            "Gen_loss:4.3462333110255713e-07\n",
            "Disc_loss:0.36189508717507124\n",
            "Gen_loss:1.858760242612334e-06\n",
            "Disc_loss:0.47157279308885336\n",
            "Gen_loss:1.825272738642525e-05\n",
            "Disc_loss:0.4148825389929698\n",
            "Gen_loss:0.000745006138458848\n",
            "Disc_loss:0.2751910647898512\n",
            "Gen_loss:0.00029251730302348733\n",
            "Disc_loss:0.20418129676454555\n",
            "Gen_loss:0.001361372647807002\n",
            "Disc_loss:0.18320771538265035\n",
            "Gen_loss:0.001139331143349409\n",
            "Disc_loss:0.1719913872707366\n",
            "Gen_loss:0.0003188838018104434\n",
            "Disc_loss:0.17198467915022775\n",
            "Gen_loss:0.0006446733605116606\n",
            "Disc_loss:0.1718378578248121\n",
            "Gen_loss:0.00034486493677832186\n",
            "Disc_loss:0.1659099840237559\n",
            "Gen_loss:0.0004015216254629195\n",
            "Disc_loss:0.16734851380215332\n",
            "Gen_loss:0.00017154899251181632\n",
            "Disc_loss:0.17444219759181578\n",
            "Gen_loss:0.0003144886577501893\n",
            "Disc_loss:0.17986015581072934\n",
            "Gen_loss:6.403304723789915e-05\n",
            "Disc_loss:0.18883906866267353\n",
            "Gen_loss:0.00027254759334027767\n",
            "Disc_loss:0.19347684613239835\n",
            "Gen_loss:0.00022622261894866824\n",
            "Disc_loss:0.173961622819661\n",
            "Gen_loss:0.0002662956540007144\n",
            "Disc_loss:0.16723447752110587\n",
            "Gen_loss:0.0001907164987642318\n",
            "Disc_loss:0.16398730105356663\n",
            "Gen_loss:0.0002736166352406144\n",
            "Disc_loss:0.1652463782002087\n",
            "Gen_loss:0.0001621391566004604\n",
            "Disc_loss:0.16840270717329986\n",
            "Gen_loss:0.000156211550347507\n",
            "Disc_loss:0.19003874351255945\n",
            "Gen_loss:1.9849326804433076e-07\n",
            "Disc_loss:0.3480530105298385\n",
            "Gen_loss:3.6037395148014184e-06\n",
            "Disc_loss:0.5096335578709841\n",
            "Gen_loss:0.0005659571033902466\n",
            "Disc_loss:0.4261719616526989\n",
            "Gen_loss:0.008975331671535969\n",
            "Disc_loss:0.31475462260365994\n",
            "Gen_loss:0.002627231180667877\n",
            "Disc_loss:0.19909224865369168\n",
            "Gen_loss:0.00024223889340646565\n",
            "Disc_loss:0.19675488525910367\n",
            "Gen_loss:5.4853859182912856e-05\n",
            "Disc_loss:0.22020217795392227\n",
            "Gen_loss:0.00021410576300695539\n",
            "Disc_loss:0.19414218288147822\n",
            "Gen_loss:0.00015180720947682858\n",
            "Disc_loss:0.18402451317888335\n",
            "Gen_loss:0.0002219553862232715\n",
            "Disc_loss:0.17991683739262498\n",
            "Gen_loss:0.00039655223372392356\n",
            "Disc_loss:0.17058896892933717\n",
            "Gen_loss:0.00011089796316809952\n",
            "Disc_loss:0.17829127187786753\n",
            "Gen_loss:0.00014388965792022645\n",
            "Disc_loss:0.19064842135776416\n",
            "Gen_loss:0.00017703117919154465\n",
            "Disc_loss:0.18269443036010102\n",
            "Gen_loss:0.00032203824957832694\n",
            "Disc_loss:0.16932260979160674\n",
            "Gen_loss:0.00010283929441357031\n",
            "Disc_loss:0.17279025366042333\n",
            "Gen_loss:0.00018366289441473782\n",
            "Disc_loss:0.1833949778074384\n",
            "Gen_loss:0.0002764620294328779\n",
            "Disc_loss:0.16695293103384756\n",
            "Gen_loss:0.0002719461335800588\n",
            "Disc_loss:0.16421562761138375\n",
            "Gen_loss:0.0001449831179343164\n",
            "Disc_loss:0.1660388603413594\n",
            "Gen_loss:0.00040602244553156197\n",
            "Disc_loss:0.1755071235465948\n",
            "Gen_loss:0.00013318005949258804\n",
            "Disc_loss:0.17104489436678705\n",
            "Gen_loss:0.00024609616957604885\n",
            "Disc_loss:0.17879760708819958\n",
            "Gen_loss:0.00013490351557265967\n",
            "Disc_loss:0.17373055838106666\n",
            "Gen_loss:0.0001342136674793437\n",
            "Disc_loss:0.19576153810157848\n",
            "Gen_loss:3.184412344126031e-05\n",
            "Disc_loss:0.2064548108892268\n",
            "Gen_loss:0.0003252605674788356\n",
            "Disc_loss:0.24313878541943268\n",
            "Gen_loss:0.0002779704227577895\n",
            "Disc_loss:0.19715332063424285\n",
            "Gen_loss:4.4341039028950036e-05\n",
            "Disc_loss:0.21895812387447222\n",
            "Gen_loss:0.0003574115107767284\n",
            "Disc_loss:0.22346791881136596\n",
            "Gen_loss:0.00024441751884296536\n",
            "Disc_loss:0.19328666431829333\n",
            "Gen_loss:8.489156607538462e-05\n",
            "Disc_loss:0.18708728228557447\n",
            "Gen_loss:0.00018184403597842902\n",
            "Disc_loss:0.1924061577883549\n",
            "Gen_loss:0.00017562962602823973\n",
            "Disc_loss:0.1745522849214467\n",
            "Gen_loss:0.0002559726417530328\n",
            "Disc_loss:0.17323685493647645\n",
            "Gen_loss:4.6105436922516674e-05\n",
            "Disc_loss:0.1979127480153693\n",
            "Gen_loss:0.00013999678776599467\n",
            "Disc_loss:0.20733092916634632\n",
            "Gen_loss:0.0001644746953388676\n",
            "Disc_loss:0.18996620246616658\n",
            "Gen_loss:0.0001402524794684723\n",
            "Disc_loss:0.17315671036340063\n",
            "Gen_loss:0.00025476558948867023\n",
            "Disc_loss:0.16676407276463578\n",
            "Gen_loss:0.00013094540918245912\n",
            "Disc_loss:0.1659828132542316\n",
            "Gen_loss:0.00020593791850842535\n",
            "Disc_loss:0.16576594457001192\n",
            "Gen_loss:0.0001676779065746814\n",
            "Disc_loss:0.1637768588734616\n",
            "Gen_loss:0.00015256149345077574\n",
            "Disc_loss:0.16474331166318734\n",
            "Gen_loss:0.00017210062651429325\n",
            "Disc_loss:0.16471083308715606\n",
            "Gen_loss:8.879866800270975e-05\n",
            "Disc_loss:0.16501141354819993\n",
            "Gen_loss:0.000243133312324062\n",
            "Disc_loss:0.1804609307728242\n",
            "Gen_loss:0.00013383226178120822\n",
            "Disc_loss:0.16561824834207073\n",
            "Gen_loss:0.0001728071365505457\n",
            "Disc_loss:0.16658087538962718\n",
            "Gen_loss:9.144537034444511e-05\n",
            "Disc_loss:0.16532537134480663\n",
            "Gen_loss:0.0001970674202311784\n",
            "Disc_loss:0.16919133146075183\n",
            "Gen_loss:8.018143125809729e-05\n",
            "Disc_loss:0.1725075282083708\n",
            "Gen_loss:0.00019786508346442133\n",
            "Disc_loss:0.1714868077833671\n",
            "Gen_loss:0.00010286192991770804\n",
            "Disc_loss:0.16496274358360097\n",
            "Gen_loss:0.00014001334784552455\n",
            "Disc_loss:0.16466296582802897\n",
            "Gen_loss:9.40625905059278e-05\n",
            "Disc_loss:0.16605965844064485\n",
            "Gen_loss:0.00018646768876351416\n",
            "Disc_loss:0.16938104118889896\n",
            "Gen_loss:9.303382830694318e-05\n",
            "Disc_loss:0.1668369387407438\n",
            "Gen_loss:0.0001674242375884205\n",
            "Disc_loss:0.16769468471466098\n",
            "Gen_loss:0.00010701258725021034\n",
            "Disc_loss:0.16586375872429926\n",
            "Gen_loss:0.00014859142538625747\n",
            "Disc_loss:0.16949077691242564\n",
            "Gen_loss:4.634771903511137e-05\n",
            "Disc_loss:0.1765526754243183\n",
            "Gen_loss:0.0001753827673383057\n",
            "Disc_loss:0.17920100031187758\n",
            "Gen_loss:6.825286254752427e-05\n",
            "Disc_loss:0.16860995464230655\n",
            "Gen_loss:0.00018250210268888623\n",
            "Disc_loss:0.16907228429045063\n",
            "Gen_loss:8.274940773844719e-05\n",
            "Disc_loss:0.16641020134557039\n",
            "Gen_loss:0.00014091149205341935\n",
            "Disc_loss:0.1681056321504002\n",
            "Gen_loss:0.00012551710824482143\n",
            "Disc_loss:0.16439323381564463\n",
            "Gen_loss:0.00014198310964275151\n",
            "Disc_loss:0.1646339894614357\n",
            "Gen_loss:4.834630453842692e-05\n",
            "Disc_loss:0.17037762355903396\n",
            "Gen_loss:0.00013911936548538506\n",
            "Disc_loss:0.18799729878082871\n",
            "Gen_loss:0.00011378170165698975\n",
            "Disc_loss:0.18165564577793702\n",
            "Gen_loss:0.00016070202400442213\n",
            "Disc_loss:0.18111460134514346\n",
            "Gen_loss:9.604654042050242e-05\n",
            "Disc_loss:0.17608488810583367\n",
            "Gen_loss:0.00015619320038240403\n",
            "Disc_loss:0.1724077512481017\n",
            "Gen_loss:0.001662657712586224\n",
            "Disc_loss:0.18193498303662636\n",
            "Gen_loss:4.404150240588933e-05\n",
            "Disc_loss:0.22762470634188503\n",
            "Gen_loss:2.7933401725022122e-05\n",
            "Disc_loss:0.3496268866583705\n",
            "Gen_loss:0.014208213426172733\n",
            "Disc_loss:0.3411352553375764\n",
            "Gen_loss:6.22380175627768e-05\n",
            "Disc_loss:0.27079298347234726\n",
            "Gen_loss:9.915522241499275e-05\n",
            "Disc_loss:0.19812133423693012\n",
            "Gen_loss:1.9447936210781336e-05\n",
            "Disc_loss:0.183028363622725\n",
            "Gen_loss:0.00010127998393727466\n",
            "Disc_loss:0.17857229757464665\n",
            "Gen_loss:4.235571759636514e-05\n",
            "Disc_loss:0.169997347635217\n",
            "Gen_loss:4.867909592576325e-05\n",
            "Disc_loss:0.1797434438012715\n",
            "Gen_loss:2.4768439743638737e-06\n",
            "Disc_loss:0.25444805377628654\n",
            "Gen_loss:2.6358149625593796e-05\n",
            "Disc_loss:0.34668002469697967\n",
            "Gen_loss:3.835402458207682e-05\n",
            "Disc_loss:0.3269055822165683\n",
            "Gen_loss:0.00034876191057264805\n",
            "Disc_loss:0.22215475502889603\n",
            "Gen_loss:0.00011334050941513851\n",
            "Disc_loss:0.22606472164625302\n",
            "Gen_loss:0.0005504813743755221\n",
            "Disc_loss:0.21718165923448396\n",
            "Gen_loss:0.0005919925170019269\n",
            "Disc_loss:0.20048725209198892\n",
            "Gen_loss:0.00019331011571921408\n",
            "Disc_loss:0.22014160294384055\n",
            "Gen_loss:0.0016068320255726576\n",
            "Disc_loss:0.20044351642172842\n",
            "Gen_loss:0.00041333321132697165\n",
            "Disc_loss:0.178919519918054\n",
            "Gen_loss:0.000850682845339179\n",
            "Disc_loss:0.17312325938746653\n",
            "Gen_loss:0.00029714941047132015\n",
            "Disc_loss:0.1678018457860162\n",
            "Gen_loss:0.0005036212387494743\n",
            "Disc_loss:0.1676191540173022\n",
            "Gen_loss:0.00019131225417368114\n",
            "Disc_loss:0.16690082613786217\n",
            "Gen_loss:0.0002270500990562141\n",
            "Disc_loss:0.18126428396863048\n",
            "Gen_loss:0.00016238531679846346\n",
            "Disc_loss:0.1682081313992967\n",
            "Gen_loss:0.0002500881382729858\n",
            "Disc_loss:0.17019649433132145\n",
            "Gen_loss:0.00014979367551859468\n",
            "Disc_loss:0.16523399030484143\n",
            "Gen_loss:0.00016478663019370288\n",
            "Disc_loss:0.163837922456878\n",
            "Gen_loss:0.00024312837922479957\n",
            "Disc_loss:0.16445923288847553\n",
            "Gen_loss:0.00023068927112035453\n",
            "Disc_loss:0.16456256361925625\n",
            "Gen_loss:0.00010209662286797538\n",
            "Disc_loss:0.1652191332032089\n",
            "Gen_loss:0.0002451043401379138\n",
            "Disc_loss:0.16547587885997928\n",
            "Gen_loss:0.00012813383364118636\n",
            "Disc_loss:0.16466737578230095\n",
            "Gen_loss:0.00015111500397324562\n",
            "Disc_loss:0.16413473173452076\n",
            "Gen_loss:0.00010958725761156529\n",
            "Disc_loss:0.1672670486586867\n",
            "Gen_loss:6.350049807224423e-05\n",
            "Disc_loss:0.1844921234587673\n",
            "Gen_loss:0.000172996282344684\n",
            "Disc_loss:0.17372073150181677\n",
            "Gen_loss:0.00010949165152851492\n",
            "Disc_loss:0.1690513619214471\n",
            "Gen_loss:0.00010318526619812474\n",
            "Disc_loss:0.17676652505542734\n",
            "Gen_loss:6.975575524847955e-05\n",
            "Disc_loss:0.17378014706628164\n",
            "Gen_loss:9.738701191963628e-05\n",
            "Disc_loss:0.18307189703045879\n",
            "Gen_loss:0.00012305939162615687\n",
            "Disc_loss:0.17041144052927848\n",
            "Gen_loss:9.440560097573325e-05\n",
            "Disc_loss:0.16886262686603004\n",
            "Gen_loss:0.0001270356005989015\n",
            "Disc_loss:0.16994133520347532\n",
            "Gen_loss:0.0017558130202814937\n",
            "Disc_loss:0.19064830749266548\n",
            "Gen_loss:0.07631473243236542\n",
            "Disc_loss:0.32903464511036873\n",
            "Gen_loss:18.186080932617188\n",
            "Disc_loss:2.7065283060073853\n",
            "Gen_loss:16.487974166870117\n",
            "Disc_loss:3.253956913948059\n",
            "Gen_loss:13.374185562133789\n",
            "Disc_loss:4.067053496837616\n",
            "Gen_loss:11.640771865844727\n",
            "Disc_loss:2.034975826740265\n",
            "Gen_loss:6.834388732910156\n",
            "Disc_loss:1.7438274323940277\n",
            "Gen_loss:4.132789134979248\n",
            "Disc_loss:2.9802303314208984\n",
            "Gen_loss:3.5276200771331787\n",
            "Disc_loss:2.661275088787079\n",
            "Gen_loss:3.2708988189697266\n",
            "Disc_loss:3.3955471515655518\n",
            "Gen_loss:3.6000800132751465\n",
            "Disc_loss:3.6741052865982056\n",
            "Gen_loss:2.0834007263183594\n",
            "Disc_loss:3.338834762573242\n",
            "Gen_loss:1.2456433773040771\n",
            "Disc_loss:3.753195881843567\n",
            "Gen_loss:7.242397308349609\n",
            "Disc_loss:2.929471641778946\n",
            "Gen_loss:4.14838981628418\n",
            "Disc_loss:2.044874429702759\n",
            "Gen_loss:3.3812427520751953\n",
            "Disc_loss:3.0847124457359314\n",
            "Gen_loss:2.2276511192321777\n",
            "Disc_loss:1.461346983909607\n",
            "Gen_loss:1.0938537120819092\n",
            "Disc_loss:1.1235200762748718\n",
            "Gen_loss:5.706774711608887\n",
            "Disc_loss:2.358883559703827\n",
            "Gen_loss:0.7372860908508301\n",
            "Disc_loss:1.9040853679180145\n",
            "Gen_loss:7.390895843505859\n",
            "Disc_loss:7.703294038772583\n",
            "Gen_loss:9.032039642333984\n",
            "Disc_loss:2.991830974817276\n",
            "Gen_loss:6.2759199142456055\n",
            "Disc_loss:3.3946125507354736\n",
            "Gen_loss:2.398831367492676\n",
            "Disc_loss:3.049099624156952\n",
            "Gen_loss:1.980413794517517\n",
            "Disc_loss:1.6776863634586334\n",
            "Gen_loss:1.0741013288497925\n",
            "Disc_loss:1.1228696703910828\n",
            "Gen_loss:0.784564733505249\n",
            "Disc_loss:1.039346992969513\n",
            "Gen_loss:0.45012250542640686\n",
            "Disc_loss:0.6239006221294403\n",
            "Gen_loss:0.43695881962776184\n",
            "Disc_loss:0.7891710102558136\n",
            "Gen_loss:0.2691776156425476\n",
            "Disc_loss:0.8861307501792908\n",
            "Gen_loss:0.5014013051986694\n",
            "Disc_loss:0.8118229806423187\n",
            "Gen_loss:0.7800255417823792\n",
            "Disc_loss:0.6488599479198456\n",
            "Gen_loss:0.5495904088020325\n",
            "Disc_loss:0.5473670065402985\n",
            "Gen_loss:0.5447009801864624\n",
            "Disc_loss:0.6057801097631454\n",
            "Gen_loss:0.6308678388595581\n",
            "Disc_loss:1.742626041173935\n",
            "Gen_loss:0.5152626037597656\n",
            "Disc_loss:0.6590292751789093\n",
            "Gen_loss:0.2383279800415039\n",
            "Disc_loss:1.5802668333053589\n",
            "Gen_loss:2.2957515716552734\n",
            "Disc_loss:0.8389944434165955\n",
            "Gen_loss:0.06254842132329941\n",
            "Disc_loss:0.4377656579017639\n",
            "Gen_loss:0.06021694839000702\n",
            "Disc_loss:0.40830831229686737\n",
            "Gen_loss:0.0013376777060329914\n",
            "Disc_loss:0.39281434565782547\n",
            "Gen_loss:0.0008354112505912781\n",
            "Disc_loss:0.3932922035455704\n",
            "Gen_loss:0.0016043325886130333\n",
            "Disc_loss:0.2655540481209755\n",
            "Gen_loss:0.036556221544742584\n",
            "Disc_loss:0.6690549850463867\n",
            "Gen_loss:0.007139685098081827\n",
            "Disc_loss:0.3521280437707901\n",
            "Gen_loss:0.002117600291967392\n",
            "Disc_loss:0.24487749952822924\n",
            "Gen_loss:0.002064583357423544\n",
            "Disc_loss:0.3310175300575793\n",
            "Gen_loss:0.012546087615191936\n",
            "Disc_loss:0.2604884169995785\n",
            "Gen_loss:0.09989582002162933\n",
            "Disc_loss:0.21481828507967293\n",
            "Gen_loss:0.004033146426081657\n",
            "Disc_loss:0.2572661004960537\n",
            "Gen_loss:2.750369071960449\n",
            "Disc_loss:0.6026295721530914\n",
            "Gen_loss:1.350757360458374\n",
            "Disc_loss:1.3110597133636475\n",
            "Gen_loss:0.47084975242614746\n",
            "Disc_loss:0.8215003609657288\n",
            "Gen_loss:0.005397905129939318\n",
            "Disc_loss:0.9293928742408752\n",
            "Gen_loss:1.4606037139892578\n",
            "Disc_loss:0.6792618930339813\n",
            "Gen_loss:0.018410511314868927\n",
            "Disc_loss:0.4498780905851163\n",
            "Gen_loss:0.009362790733575821\n",
            "Disc_loss:1.872020035982132\n",
            "Gen_loss:0.003629266982898116\n",
            "Disc_loss:0.6863485127687454\n",
            "Gen_loss:6.213071901584044e-05\n",
            "Disc_loss:0.5453634224832058\n",
            "Gen_loss:6.0470767493825406e-05\n",
            "Disc_loss:0.3128341380506754\n",
            "Gen_loss:0.001398285385221243\n",
            "Disc_loss:0.3529549017548561\n",
            "Gen_loss:0.011937012895941734\n",
            "Disc_loss:0.23643062263727188\n",
            "Gen_loss:0.006675010547041893\n",
            "Disc_loss:0.2367840267252177\n",
            "Gen_loss:0.005284050479531288\n",
            "Disc_loss:0.5462799817323685\n",
            "Gen_loss:0.046693384647369385\n",
            "Disc_loss:0.2910686959512532\n",
            "Gen_loss:10.594016075134277\n",
            "Disc_loss:0.4451436996459961\n",
            "Gen_loss:3.883132219314575\n",
            "Disc_loss:7.104713141918182\n",
            "Gen_loss:8.791583061218262\n",
            "Disc_loss:1.8471788465976715\n",
            "Gen_loss:5.985814094543457\n",
            "Disc_loss:0.9412716627120972\n",
            "Gen_loss:4.766650199890137\n",
            "Disc_loss:1.8175479173660278\n",
            "Gen_loss:4.4102463722229\n",
            "Disc_loss:1.740335762500763\n",
            "Gen_loss:4.873661994934082\n",
            "Disc_loss:2.271881937980652\n",
            "Gen_loss:5.389017105102539\n",
            "Disc_loss:2.154114305973053\n",
            "Gen_loss:3.952164888381958\n",
            "Disc_loss:2.41302827000618\n",
            "Gen_loss:3.0927581787109375\n",
            "Disc_loss:2.4567198753356934\n",
            "Gen_loss:3.1099162101745605\n",
            "Disc_loss:1.6268166303634644\n",
            "Gen_loss:3.1029155254364014\n",
            "Disc_loss:1.6456914246082306\n",
            "Gen_loss:3.364264488220215\n",
            "Disc_loss:1.8736981749534607\n",
            "Gen_loss:2.9808154106140137\n",
            "Disc_loss:1.2748696208000183\n",
            "Gen_loss:3.023256301879883\n",
            "Disc_loss:2.9262431859970093\n",
            "Gen_loss:4.012732982635498\n",
            "Disc_loss:2.3382903933525085\n",
            "Gen_loss:4.354545593261719\n",
            "Disc_loss:1.6335135698318481\n",
            "Gen_loss:3.1810238361358643\n",
            "Disc_loss:1.7244170755147934\n",
            "Gen_loss:3.204698085784912\n",
            "Disc_loss:0.9718796759843826\n",
            "Gen_loss:3.208827495574951\n",
            "Disc_loss:1.4208864271640778\n",
            "Gen_loss:3.6385481357574463\n",
            "Disc_loss:1.245561122894287\n",
            "Gen_loss:2.9611737728118896\n",
            "Disc_loss:1.0040020048618317\n",
            "Gen_loss:2.185595989227295\n",
            "Disc_loss:0.8563136458396912\n",
            "Gen_loss:2.042919874191284\n",
            "Disc_loss:1.224806621670723\n",
            "Gen_loss:1.303885579109192\n",
            "Disc_loss:0.8007655590772629\n",
            "Gen_loss:0.7973687648773193\n",
            "Disc_loss:1.1003901362419128\n",
            "Gen_loss:1.239601731300354\n",
            "Disc_loss:0.7908250093460083\n",
            "Gen_loss:1.4254279136657715\n",
            "Disc_loss:0.8475752472877502\n",
            "Gen_loss:1.006190538406372\n",
            "Disc_loss:0.5295186340808868\n",
            "Gen_loss:0.9261894226074219\n",
            "Disc_loss:0.7125168144702911\n",
            "Gen_loss:0.7426260709762573\n",
            "Disc_loss:0.451083242893219\n",
            "Gen_loss:0.5966750979423523\n",
            "Disc_loss:0.4291532635688782\n",
            "Gen_loss:0.16912847757339478\n",
            "Disc_loss:0.33626948297023773\n",
            "Gen_loss:0.9705201387405396\n",
            "Disc_loss:1.082010805606842\n",
            "Gen_loss:0.47524750232696533\n",
            "Disc_loss:0.6101814806461334\n",
            "Gen_loss:0.11479803174734116\n",
            "Disc_loss:0.4923129975795746\n",
            "Gen_loss:0.3894153833389282\n",
            "Disc_loss:0.338961660861969\n",
            "Gen_loss:0.19294868409633636\n",
            "Disc_loss:0.4405791908502579\n",
            "Gen_loss:0.18079569935798645\n",
            "Disc_loss:0.2756066247820854\n",
            "Gen_loss:0.12976618111133575\n",
            "Disc_loss:0.9878866672515869\n",
            "Gen_loss:0.8838528394699097\n",
            "Disc_loss:0.3832818269729614\n",
            "Gen_loss:1.0906038284301758\n",
            "Disc_loss:0.8855004906654358\n",
            "Gen_loss:0.28320053219795227\n",
            "Disc_loss:0.30061381310224533\n",
            "Gen_loss:0.1734849065542221\n",
            "Disc_loss:0.37402231246232986\n",
            "Gen_loss:0.6931297779083252\n",
            "Disc_loss:0.5640132129192352\n",
            "Gen_loss:0.35111790895462036\n",
            "Disc_loss:0.29631129652261734\n",
            "Gen_loss:0.12285303324460983\n",
            "Disc_loss:0.3366227000951767\n",
            "Gen_loss:0.0723303034901619\n",
            "Disc_loss:0.3564015179872513\n",
            "Gen_loss:0.27217328548431396\n",
            "Disc_loss:0.46177442371845245\n",
            "Gen_loss:0.9192057251930237\n",
            "Disc_loss:0.3153320513665676\n",
            "Gen_loss:0.11747857928276062\n",
            "Disc_loss:0.550207257270813\n",
            "Gen_loss:0.16191157698631287\n",
            "Disc_loss:0.258283831179142\n",
            "Gen_loss:0.03895621746778488\n",
            "Disc_loss:0.22952055372297764\n",
            "Gen_loss:0.018080178648233414\n",
            "Disc_loss:0.2224244847893715\n",
            "Gen_loss:0.08085896074771881\n",
            "Disc_loss:0.29401394724845886\n",
            "Gen_loss:0.09149791300296783\n",
            "Disc_loss:0.22246195003390312\n",
            "Gen_loss:0.03671393543481827\n",
            "Disc_loss:0.2717825323343277\n",
            "Gen_loss:0.01933423802256584\n",
            "Disc_loss:0.2172620240598917\n",
            "Gen_loss:0.02871871553361416\n",
            "Disc_loss:0.21120913606137037\n",
            "Gen_loss:0.06281575560569763\n",
            "Disc_loss:0.1927402475848794\n",
            "Gen_loss:1.7439494132995605\n",
            "Disc_loss:0.5701965689659119\n",
            "Gen_loss:2.7204158306121826\n",
            "Disc_loss:0.22101053968071938\n",
            "Gen_loss:3.1710152626037598\n",
            "Disc_loss:1.5584293901920319\n",
            "Gen_loss:2.369208335876465\n",
            "Disc_loss:0.9103341698646545\n",
            "Gen_loss:0.8687033653259277\n",
            "Disc_loss:0.5948217809200287\n",
            "Gen_loss:0.8042152523994446\n",
            "Disc_loss:0.9612244367599487\n",
            "Gen_loss:0.17507712543010712\n",
            "Disc_loss:0.619108073413372\n",
            "Gen_loss:0.33792588114738464\n",
            "Disc_loss:0.43980872631073\n",
            "Gen_loss:0.6290211081504822\n",
            "Disc_loss:0.5683893859386444\n",
            "Gen_loss:0.03810056298971176\n",
            "Disc_loss:0.3104449436068535\n",
            "Gen_loss:0.021620912477374077\n",
            "Disc_loss:0.2500985637307167\n",
            "Gen_loss:0.06843970715999603\n",
            "Disc_loss:0.2884079236537218\n",
            "Gen_loss:0.003373988438397646\n",
            "Disc_loss:0.2318744994699955\n",
            "Gen_loss:0.4264523386955261\n",
            "Disc_loss:0.4623078852891922\n",
            "Gen_loss:1.0455902814865112\n",
            "Disc_loss:0.2604050049558282\n",
            "Gen_loss:0.786255955696106\n",
            "Disc_loss:0.5490433573722839\n",
            "Gen_loss:0.01287824846804142\n",
            "Disc_loss:0.28374986548442394\n",
            "Gen_loss:0.008790630847215652\n",
            "Disc_loss:0.2524067284539342\n",
            "Gen_loss:0.0322500616312027\n",
            "Disc_loss:0.4179154187440872\n",
            "Gen_loss:0.10971076786518097\n",
            "Disc_loss:0.3497444689273834\n",
            "Gen_loss:0.8533869981765747\n",
            "Disc_loss:0.4802405536174774\n",
            "Gen_loss:0.0347093790769577\n",
            "Disc_loss:0.22771071549504995\n",
            "Gen_loss:2.4336917400360107\n",
            "Disc_loss:0.4992903769016266\n",
            "Gen_loss:0.024194026365876198\n",
            "Disc_loss:0.3761618323624134\n",
            "Gen_loss:0.0036016819067299366\n",
            "Disc_loss:0.28289052844047546\n",
            "Gen_loss:0.005013881716877222\n",
            "Disc_loss:0.2731190696358681\n",
            "Gen_loss:0.0015408855397254229\n",
            "Disc_loss:0.245646171271801\n",
            "Gen_loss:0.001547676743939519\n",
            "Disc_loss:0.38094981014728546\n",
            "Gen_loss:0.0984496921300888\n",
            "Disc_loss:0.23214320023544133\n",
            "Gen_loss:0.17107947170734406\n",
            "Disc_loss:0.1991887299809605\n",
            "Gen_loss:0.45254629850387573\n",
            "Disc_loss:0.429348960518837\n",
            "Gen_loss:0.34405744075775146\n",
            "Disc_loss:0.5072417072951794\n",
            "Gen_loss:0.005395933520048857\n",
            "Disc_loss:0.5099457055330276\n",
            "Gen_loss:0.10777358710765839\n",
            "Disc_loss:0.3329405812546611\n",
            "Gen_loss:0.12584084272384644\n",
            "Disc_loss:0.2662476981058717\n",
            "Gen_loss:0.002639027312397957\n",
            "Disc_loss:0.306010190397501\n",
            "Gen_loss:0.10086309909820557\n",
            "Disc_loss:0.2588932365179062\n",
            "Gen_loss:0.8183584213256836\n",
            "Disc_loss:0.3691595494747162\n",
            "Gen_loss:0.02289428561925888\n",
            "Disc_loss:0.3049029801040888\n",
            "Gen_loss:0.002440189942717552\n",
            "Disc_loss:0.3383786454796791\n",
            "Gen_loss:0.013549474067986012\n",
            "Disc_loss:0.32287566363811493\n",
            "Gen_loss:0.08967650681734085\n",
            "Disc_loss:0.2901757783256471\n",
            "Gen_loss:0.0043533556163311005\n",
            "Disc_loss:0.2678588358685374\n",
            "Gen_loss:0.001831137458793819\n",
            "Disc_loss:0.2608196968212724\n",
            "Gen_loss:0.002374527510255575\n",
            "Disc_loss:0.27772854271461256\n",
            "Gen_loss:0.0013490793062373996\n",
            "Disc_loss:0.31488571502268314\n",
            "Gen_loss:1.9459463357925415\n",
            "Disc_loss:0.6297674477100372\n",
            "Gen_loss:0.07992969453334808\n",
            "Disc_loss:0.24379942612722516\n",
            "Gen_loss:0.03592647612094879\n",
            "Disc_loss:0.22946046805009246\n",
            "Gen_loss:0.02074911817908287\n",
            "Disc_loss:0.2608898878097534\n",
            "Gen_loss:0.010248782113194466\n",
            "Disc_loss:0.21410320326685905\n",
            "Gen_loss:0.0033273485023528337\n",
            "Disc_loss:0.20961435127537698\n",
            "Gen_loss:0.0008623139001429081\n",
            "Disc_loss:0.21024120040237904\n",
            "Gen_loss:0.001454137614928186\n",
            "Disc_loss:0.1877757371403277\n",
            "Gen_loss:0.039488133043050766\n",
            "Disc_loss:0.2620429340749979\n",
            "Gen_loss:0.2029183804988861\n",
            "Disc_loss:0.48037000000476837\n",
            "Gen_loss:0.2512056231498718\n",
            "Disc_loss:0.2730810157954693\n",
            "Gen_loss:0.055071547627449036\n",
            "Disc_loss:0.22428487986326218\n",
            "Gen_loss:0.009981758892536163\n",
            "Disc_loss:0.22484841058030725\n",
            "Gen_loss:0.042306557297706604\n",
            "Disc_loss:0.22563445894047618\n",
            "Gen_loss:0.012674551457166672\n",
            "Disc_loss:0.31778883934020996\n",
            "Gen_loss:0.5635261535644531\n",
            "Disc_loss:1.0055869817733765\n",
            "Gen_loss:0.2192893922328949\n",
            "Disc_loss:0.30058979430032196\n",
            "Gen_loss:0.3577888011932373\n",
            "Disc_loss:0.29789783990418073\n",
            "Gen_loss:0.0750342309474945\n",
            "Disc_loss:0.5385925471782684\n",
            "Gen_loss:3.044658660888672\n",
            "Disc_loss:0.22852777782827616\n",
            "Gen_loss:4.995550155639648\n",
            "Disc_loss:1.392456978559494\n",
            "Gen_loss:0.4456048607826233\n",
            "Disc_loss:0.2759644016623497\n",
            "Gen_loss:1.1730339527130127\n",
            "Disc_loss:1.7927502393722534\n",
            "Gen_loss:0.023773346096277237\n",
            "Disc_loss:0.31279297173023224\n",
            "Gen_loss:0.004016160499304533\n",
            "Disc_loss:0.8768202662467957\n",
            "Gen_loss:0.7777136564254761\n",
            "Disc_loss:0.2942541749216616\n",
            "Gen_loss:0.48196402192115784\n",
            "Disc_loss:0.4792885333299637\n",
            "Gen_loss:0.09745776653289795\n",
            "Disc_loss:0.31934585981070995\n",
            "Gen_loss:0.016876263543963432\n",
            "Disc_loss:0.270622193813324\n",
            "Gen_loss:0.21335220336914062\n",
            "Disc_loss:0.37551605701446533\n",
            "Gen_loss:0.04770226776599884\n",
            "Disc_loss:0.675012081861496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-aa7f18c37205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m main(DATASET_PATH, BASE_MODELS_PATH, BASE_RESULTS_PATH, process_load_images=False,\n\u001b[0;32m--> 495\u001b[0;31m      TRAIN_GAN = True, TRAIN_ENCODER = False, TRAIN_ENC_GAN = False)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-aa7f18c37205>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(DATASET_PATH, BASE_MODELS_PATH, BASE_RESULTS_PATH, process_load_images, TRAIN_GAN, TRAIN_ENCODER, TRAIN_ENC_GAN)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0my_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0mreconstructed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlatent_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_curr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0md_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_curr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0md_recons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreconstructed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_curr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1816\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict_on_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1818\u001b[0;31m       \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_batch_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1819\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msingle_batch_iterator\u001b[0;34m(strategy, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1511\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1513\u001b[0;31m   \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1514\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1527\u001b[0m           label, \", \".join(str(i.shape[0]) for i in nest.flatten(single_data)))\n\u001b[1;32m   1528\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 128, 14\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXanGtqjNsiR"
      },
      "source": [
        "! cp loaded_images.npy '/content/drive/MyDrive/Face Aging/cGAN/models/loaded_images.np'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9a-vHaoFmN3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsenM7YQ6tTT"
      },
      "source": [
        "!mkdir -p '/content/drive/MyDrive/Face Aging/data/wiki_crop'\n",
        "!cp -R wiki_crop /content/{repo_name}/face_app/data/wiki_crop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp8iGI2L7OKu"
      },
      "source": [
        "!ls '/content/drive/MyDrive/Face Aging/data/wiki_crop'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDjGB0Tj8ocK",
        "outputId": "233eabc6-25c7-4120-ed04-9937c74e2931"
      },
      "source": [
        "!ls /content/{repo_name}/face_app"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t\t  __init__.py  notebook   requirements.txt\n",
            "data_download.py  model.py     README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh8oxDO25QoC"
      },
      "source": [
        ""
      ]
    }
  ]
}